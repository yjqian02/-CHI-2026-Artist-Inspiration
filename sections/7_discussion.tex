\section{Discussion}

\subsection{Supporting Artistic Skill-building via Enhanced Agency \& Control}
\todo{Alice's thought: I think we should have a section about the immense opportunity we found in designing tools to help artists build skills rather than like replace them -- we can maybe cite some of the learning sciences lit Haiyi was talking about for the proposal?}
\jh{agreed!}

\begin{itemize}
    \item At individual levels: 2d \& 3d artists perceive artistic control differently
    \item involving community engagement \& feedback or environmental factors
\end{itemize}

==== copied over from proposal, if we want to include in discussion ====

Our next aim is to use \textbf{scaffolding} techniques inspired by the learning sciences~\citep{gibbons2002scaffolding}, where temporary support is provided to help a learner complete a task beyond their current unaided ability, but gradually removed to improve the capabilities, creativity, and independence of novice artists over time. Applying scaffolding is a major challenge since modern  generative AI is not transparent, with limited abilities to `unlearn' knowledge~\citep{bourtoule2021machine}, and easy hackable~\citep{wei2023jailbroken}. To tackle this, we will design our system as a set of modules strictly partitioned to enable unlearning, and with strict guardrails so users cannot access removed capabilities during scaffolding. We will base our design on best practices in designing educational tools. Novice artists will have access to full scaffolding (e.g., step-by-step sketching, adaptations, and recombinations) at the beginning. As they progress, the scaffolding will be gradually removed. We will co-design and pilot-test the system with both novice and experienced artists, as well as educators. 

We will measure upskilling through a combination of self-assessment scales from the education literature, performance-based tasks that track improvement pre-and post- system integration as well as a series of longitudinal user studies. In addition to improving novice artist capabilities, our system will also improve their creativity through challenging them to deviate from historical styles and help creativity and personalization. More broadly, this creativity scaffolding has implications for other domains where humanâ€“AI collaboration is critical, including design, education, and knowledge work, pointing toward new ways of using AI not just to automate but to cultivate human creativity and growth.





\subsection{Policy Recommendations for ethical development/training AI/compensation}
Our analysis points to the importance of policy that guides the positive use of these tools so novice artists can build skills while avoiding exploitation. Prior work documents a history of harm to artists in AI development, including unconsented training\todo{cite}, weakened attribution and compensation~\cite{kawakami2024impact, foreground}, and the straightening of expression through biased and homogenized outputs \cite{unstraighten}. We read our findings as prompts for community dialogue and governance rather than fixed prescriptions. Trust rests first on consent, compensation, and provenance. Participants linked willingness to use integrated features to permission and pay, and asked for visible signals about where data came from. As such, it may be beneficial to favor public domain or opt in licensed data, compensate contributors, and make provenance and labeling visible across search, editing, and sharing so creators know what they are using. Clear source tracing and labeling also reduce the risk that novices inadvertently treat synthetic images as authoritative references.

Policies should also preserve agency while still offering help. Participants welcomed guidance that teaches and scaffolds, provided it does not steer the work or collapse stylistic diversity. Sensible defaults include opt-in guidance with visible intent checks, multiple procedural paths rather than a single route, and feedback that is confident where ground truth exists, such as anatomy, perspective, and lighting, while remaining non-prescriptive for subjective choices like style or palette. When tools produce references for pose, perspective, or lighting, accuracy safeguards and quality warnings are prudent so learners are not taught the wrong thing, especially in 3D reference workflows.

Finally, participants imagined community infrastructure that supports learning without eroding integrity. Provenance-rich spaces that share processes and remixes, coupled with privacy and consent controls, are more likely to sustain participation and skill building\todo{connection to related work and citations}. Several participants also raised environmental costs, which suggests disclosure of energy and emissions and greener defaults as part of responsible deployment\todo{citations}. In sum, our findings motivate higher level guidelines and accountability across development, use, and audit. 



\subsection{Limitations \& Future Work}