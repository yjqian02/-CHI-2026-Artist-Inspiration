\section{Related Work}
Below, we first overview theory and empircal findings around the artistic creation process and steps, followed by existing creativity support tools for visual artists and designers. Finally, we summarize literature capturing artistic community perceptions and concerns around generative AI support tools, and compare these with recent excitement for around more democratized opportunities for artistic creation to surface a key gap for supporting early-stage workflows of novice artists, which we aim to address in this study.

\subsection{Creative Workflows of (Professional) Visual Artists}
Visual art creation is complex, iterative and resource-intensive process, containing subprocesses and tasks that vary widely depending on the artists' expertise, intentions, as well as the choice and availability of materials, medium and aesthetics \cite{multivariate, subproccess}. Since an entire century ago, psychology scholars sought to model the stages and dimensions of the artistic creation process:
\citet{wallas} proposed the four macroprocesses of \textit{preparation}, \textit{incubation}, \textit{illumination}, and \textit{revision} \cite{wallas, wallas_followup}, 
\citet{soi} introduced \textit{divergent} and \textit{convergent} thinking, \citet{vision} identified the \textit{problem formulation} and \textit{solution} stages (pre-drawing versus during drawing and feedback), while \citet{geneplore} separated the creative activity into the \textit{generate} and \textit{explore} processes. 

More empirically, \citet{modeling} offered the first grounded macro-process model of professional artmaking, which consisted of (1) \textit{artwork conception} (2) \textit{idea development} (3) \textit{making of the artwork} and (4) \textit{finishing the artwork}. The first step of \textit{conception} also implicates (sub)processes of orientation \cite{osborn}, \textit{preparation} \cite{wallas}, \textit{concentration} \cite{ecological} and \textit{a goal of creation} \cite{furst}. The second step (\textit{idea development}) --- wherein the artist (re)structures the idea --- is highly tied to the relaxed and subconscious idea-association process of \textit{incubation} \cite{wallas} as well as \textit{intimation} \cite{wallas_followup}, which lead to \textit{insight} -- the illuminating moment when an idea or image emerges, a process that requires prior thinking \cite{boden}. Then, the \textit{(3) making of the artwork} describes where the idea is realized. Finally, the \textit{(4) finalization} step or \textit{validation} occurs -- where the art might be deemed complete, get elaborated on, or even abandoned. To better situate artistic process in the creator's life and contexts, \citet{multivariate} took a more action-oriented framework to qualitatively reconstruct professional workflows, finding additional stages including the \textit{documentation and reflection} phase between \textit{(1) artwork conception} and \textit{(2) idea development} where the artists gathers information about required materials and technologies, as well as the refinement of \textit{(3) making of the artwork} into subprocesses of \textit{first sketches} and the \textit{testing of forms and ideas} that origniate from reflection.

But while professional artmaking has been extensively examined, the literature around student (or novice) artist practices remains relatively sparse --- leaving their wandering, nonlinear and unsystematic approaches underexplored \cite{ecological, mfa, modification}. The handful exceptions offered (1) insights that novices engage relatively more with earlier stages of the professional practice --- e.g., idea conception, documentation and development, discovery-oriented behaviors \cite{solving} --- since they are still learning how to produce and evaluate ideas and (2) an inventory of 17 stages of novice artists' practices, where key early processes included immersion, reflection, inspiration, research, ideation and selection \cite{botella2018stages}. Despite such detailed inventory of cognitive microprocesses, there remains a gap in understanding how novice artists interact with digital mediums \cite{cocreative} or technology support during their creative processes, which this study aims to addresss.


\subsection{Co-Creative AI-Support Tools for Early-Stage Artmaking}

Meanwhile, studies at the intersection of the CHI and UIST communities showcase various forms of digital creativity support tools \cite{centric, PortraitSketch, k_sketch}, some of which even center novice artists \cite{bob} while others adapt generative AI systems for co-creation~\cite{wang2025aideation, o2015designscape, ko2023large, fan2024contextcam, Midjourney, AdobeFirefly, everybody_sketch}.
Following the taxonomy of multimodal image-text generative models~\cite{liang2024foundations}, we categorize these co-creative AI systems into (1) summarization tools that reduce information content by highlighting salient parts of inputs, (2) translation methods that modify or edit information along dimensions while keeping other desired attributes consistent, and (3) creation tools that generate data and increase information content while maintaining coherence and controllability.

\textit{Summarization}-based approaches highlight specific parts of visual inputs ~\citep{kong2019understanding}, strip away details to obtain simpler sketches~\citep{swiftsketch}, or summarize the image using key attributes or database references~\citep{sermuga2021uisketch}. Such tools support (1) data visualization in storytelling and presentation~\citep{kong2019understanding}, indexing and retrieving relevant user interfaces for designers~\citep{sermuga2021uisketch}, as well as in summarizing visual interfaces into short language phrases for easier user understanding~\citep{wang2021screen2words}. Summarization-based approaches also decompose visual content into multiple sub-parts including step-by-step tutorials~\citep{PaintsUNDO} or stroke references~\citep{neutralstroke}, which can support artists in learning techniques for achieving specific effects, in addition to making the creative process more transparent. By highlighting key steps, summarization-based approaches also afford users
fine-grained control over the drawing process~\citep{paintsalter}.
% highlighted steps often enable users to have 

\textit{Translation} approaches for co-creation can be performed using retrieval, generation, or editing. Retrieval-based methods return relevant visual information in a manner that is semantic similar, such as retrieving images based on textual descriptions~\cite{GenQuery, VSC}, multiple references~\citep{OrganizingPhoto}, or based on target attributes such as color, material, and style~\citep{wu2025qwen, gpt4v, liu2024llavanext}. Generative versions have also been proposed, particularly in developing more interactive text-to-image generative models that automatically refine text prompts to improve user satisfaction~\citep{wang2024promptcharm} and diversify the output space of generated images for personalization~\citep{poet}. Editing-based approaches seek to maintain a portion of the information, such as visual styles, while making targeted changes to the other parts like content or backgrounds. Recent advances in generative AI have enabled fine-grained style transfer and medium adaptation through lightweight model tuning techniques~\citep{blora, flux}, perspective or background changes with multimodal editing tools~\citep{wu2025qwen, backgroundremove}. A related line of work explores visual editing through direct manipulation, allowing designers to annotate or draw on an image and supplement these edits with text descriptions, thereby reducing reliance on purely textual prompts and giving users greater agency over the generative process~\cite{liu2025magicquill, ati}.

Finally, \textit{creation} extends the information in a consistent way, often based on targeted sampling from generative models. For example, recent work has investigated how multiple elements from different source images or sketches can be combined in a consistent manner to produce new compositions~\cite{magiccolor, yan2025imagereferencedsketchcolorization}. Other tools convert 2D inputs into 3D assets for spatial exploration across multiple views in a geometrically-consistent manner~\citep{trellis, wang2024gaussianeditor, li2025voxhammer, brooks2023instructpix2pix}. Finally, image-to-video generative models help convert a web page into short videos to support designers in marketing~\citep{chi2020automatic} and can convert documents into narrated instructional videos for education~\citep{chi2022synthesis}.

% \iffalse
% in purple from figma

% summarize
% - search for objects in an image
% - Detail zoom-in
% - image layer break down

% translate
% - translate visual content into text for semantic clusterings
% - Pose-change
% - change in perspective (including background)
% - keyword-based image editing

% create
% - combine elements/references into one on top of sketch structure
% - create accurate images by separately generating and combining each attribute-object pair from a text prompt



% decoding the following elements and provide analysis/interactive data visualizations to reveal patterns and trends in art across historical periods


% query concretization, image-based modification, and 
% Qwen-Image




% \todo{visual artists are not necessarily AI artists...really don't want to generate final art pieces}

% \begin{itemize}
%     \item digital art processes: \cite{camba2018conceptual}
%     % \item 
% \end{itemize}

% \fi

Collectively, these systems highlight the growing potential of AI tools to not only generate and retrieve but also summarize, recombine, and transform references in ways that support iterative and exploratory workflows. 
However, much of this work centers on professional designers and commercial outcomes rather than artistic self-expression or learning. Our work addresses this gap by focusing on the early-stage inspiration workflows of novice artists to explore how AI can serve as a partner in their creative exploration, instead of as a tool to produce finished works.


\subsection{Artists' Perceptions of Generative AI versus Visions of Democratization and Access}

Such recent advances spurs a wave of excitement for the transformative potential of generative AI for democratizing access to the artmaking process. \citet{chatterjee} outlines its power potential to produce emotional and evocative works, as well as to challenge traditional notions of aesthetics -- thereby democratizing art ``by making the tools of artistic creation accessible to a broader audience'' \cite{liberation}. \citet{imperial} argues that generative AI have been facilitated to serve as a new form of every day life, extending the \textit{imperical mode of living} into the sphere of everyday aesthetic production. 
  
But despite the potential for generative AI to support artistic co-creation, the artistic community remains skeptical and threatened by their potential to plagiarize \citep{shi2023understanding}, harm rights over attribution and ownership \citep{lima} as well as unfair models of compensation~\citep{kawakami2024impact, foreground} --- prompting calls for more inclusive and decolonial futures of AI in the arts~\citep{decolonial}.
~\citet{giacomin2023intersection} highlighted contested debates surrounding copyright issues, ethical and legal concerns, the impact on the art industry, questions of authorship and authenticity as well as how AI reshapes our understanding of creativity and art itself.
~\citet{decline_novelty} found peak artwork content novelty to increase over time but average novelty to decline, suggesting an expanding but inefficient idea space, which calls for more harmonious blending of human exploration and AI exploitation. 
Finally,~\citet{unstraighten} found queer artists to struggle in using these models due to various embedded normative values, such as hyper-positivity and anti-sexuality.


A key factor impacting artists' perception of generative AI is their level of experience. Experienced visual professionals with more confidence in their originality, creativity, and empathic skills were more likely to find generative AI's role as assistive~\citep{li2024user, kawakami2024impact}. 
Meanwhile, skill degradation, job replacement, and creativity exhaustion adversely impact junior workflows~\citep{li2024user}.
\citet{epstein2023art} proposes that disruptive technological advances will not necessarily end all human artistic creation, but rather produce more complex effects and shifts in aesthetics, roles and practices. ~\citet{ko2023large} and~\citet{inie2023designing} both found significant potential and new conceptions on what constitutes creativity in relation to generative AI --- acknowledging AI's versatile roles with high usability to support creative works in automating the creation process (i.e., automation), expanding their ideas (i.e., exploration), and facilitating or arbitrating communication (i.e., mediation). But despite such visions to support the artistic creation process, the current body of work falls short in understanding how such digital and generative forms of support align with grounded needs of \textit{novice} artists \cite{student_ai}, who represent a much broader segment of the artistic community than professional or commercial practitioners. Our work strives to not only characterize ways that novice artists currently perceive and use generative support in their workflows, but to also understand how their common challenges may align with emerging technical capabilities.




